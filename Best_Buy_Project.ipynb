{"cells":[{"cell_type":"markdown","metadata":{"id":"2811b154"},"source":["# Predicting slow-selling SKUs sales\n","\n","___\n","\n","**1. Overview of the Dataset** <br>\n","**2. Feature Creation** <br>\n","**3. Exploration**<br>\n","**4. Data Cleaning**<br>\n","**5. Feature Engineering**<br>\n","**6. Modeling**<br>\n","**7. Individual Prophet Prediction**<br>\n","**8. All SKUs Prediction Using Prophet**<br>\n","**9. Holt-Winters Exponential Smoothing Model**<br>\n"],"id":"2811b154"},{"cell_type":"markdown","metadata":{"id":"3ab7d9c5"},"source":["___\n","## Overview of the Dataset\n","First, we import the necessary packages for this project:\n"],"id":"3ab7d9c5"},{"cell_type":"code","source":["!pip install chart_studio\n","!pip install prophet"],"metadata":{"id":"vBFxlS96BvOG","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1674190467358,"user_tz":300,"elapsed":6169,"user":{"displayName":"Zongzhen Lin","userId":"14005131449780649529"}},"outputId":"62e2c41c-d7f8-4863-f111-e5739803af2b"},"id":"vBFxlS96BvOG","execution_count":44,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: chart_studio in /usr/local/lib/python3.8/dist-packages (1.1.0)\n","Requirement already satisfied: plotly in /usr/local/lib/python3.8/dist-packages (from chart_studio) (5.5.0)\n","Requirement already satisfied: retrying>=1.3.3 in /usr/local/lib/python3.8/dist-packages (from chart_studio) (1.3.4)\n","Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from chart_studio) (1.15.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from chart_studio) (2.25.1)\n","Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.8/dist-packages (from plotly->chart_studio) (8.1.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->chart_studio) (2022.12.7)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->chart_studio) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->chart_studio) (2.10)\n","Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->chart_studio) (4.0.0)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: prophet in /usr/local/lib/python3.8/dist-packages (1.1.1)\n","Requirement already satisfied: matplotlib>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from prophet) (3.2.2)\n","Requirement already satisfied: convertdate>=2.1.2 in /usr/local/lib/python3.8/dist-packages (from prophet) (2.4.0)\n","Requirement already satisfied: setuptools>=42 in /usr/local/lib/python3.8/dist-packages (from prophet) (57.4.0)\n","Requirement already satisfied: wheel>=0.37.0 in /usr/local/lib/python3.8/dist-packages (from prophet) (0.38.4)\n","Requirement already satisfied: holidays>=0.14.2 in /usr/local/lib/python3.8/dist-packages (from prophet) (0.18)\n","Requirement already satisfied: pandas>=1.0.4 in /usr/local/lib/python3.8/dist-packages (from prophet) (1.3.5)\n","Requirement already satisfied: python-dateutil>=2.8.0 in /usr/local/lib/python3.8/dist-packages (from prophet) (2.8.2)\n","Requirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.8/dist-packages (from prophet) (1.21.6)\n","Requirement already satisfied: setuptools-git>=1.2 in /usr/local/lib/python3.8/dist-packages (from prophet) (1.2)\n","Requirement already satisfied: tqdm>=4.36.1 in /usr/local/lib/python3.8/dist-packages (from prophet) (4.64.1)\n","Requirement already satisfied: LunarCalendar>=0.0.9 in /usr/local/lib/python3.8/dist-packages (from prophet) (0.0.9)\n","Requirement already satisfied: cmdstanpy>=1.0.4 in /usr/local/lib/python3.8/dist-packages (from prophet) (1.0.8)\n","Requirement already satisfied: pymeeus<=1,>=0.3.13 in /usr/local/lib/python3.8/dist-packages (from convertdate>=2.1.2->prophet) (0.5.12)\n","Requirement already satisfied: korean-lunar-calendar in /usr/local/lib/python3.8/dist-packages (from holidays>=0.14.2->prophet) (0.3.1)\n","Requirement already satisfied: hijri-converter in /usr/local/lib/python3.8/dist-packages (from holidays>=0.14.2->prophet) (2.2.4)\n","Requirement already satisfied: ephem>=3.7.5.3 in /usr/local/lib/python3.8/dist-packages (from LunarCalendar>=0.0.9->prophet) (4.1.4)\n","Requirement already satisfied: pytz in /usr/local/lib/python3.8/dist-packages (from LunarCalendar>=0.0.9->prophet) (2022.7)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=2.0.0->prophet) (3.0.9)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=2.0.0->prophet) (1.4.4)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=2.0.0->prophet) (0.11.0)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.8.0->prophet) (1.15.0)\n"]}]},{"cell_type":"code","execution_count":45,"metadata":{"id":"540abeab","executionInfo":{"status":"ok","timestamp":1674190467359,"user_tz":300,"elapsed":11,"user":{"displayName":"Zongzhen Lin","userId":"14005131449780649529"}}},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import seaborn as sns\n","import matplotlib\n","import matplotlib.pyplot as plt\n","import warnings\n","import math\n","import chart_studio as py\n","import plotly.graph_objs as go\n","from plotly.offline import init_notebook_mode, iplot\n","from time import time\n","from collections import defaultdict\n","\n","#sklearn packages below:\n","from statsmodels.formula import api\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.preprocessing import MinMaxScaler\n","from sklearn.model_selection import train_test_split\n","from statsmodels.stats.outliers_influence import variance_inflation_factor\n","import statsmodels.api as sm\n","\n","from sklearn.decomposition import PCA\n","from sklearn.linear_model import LinearRegression\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.ensemble import RandomForestRegressor\n","from sklearn.preprocessing import PolynomialFeatures\n","from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n","\n","import xgboost as xgb\n","from xgboost import XGBRegressor\n","from xgboost import plot_importance\n","\n","import holidays\n","from prophet import Prophet"],"id":"540abeab"},{"cell_type":"code","execution_count":46,"metadata":{"id":"a5a06d0e","executionInfo":{"status":"ok","timestamp":1674190467359,"user_tz":300,"elapsed":9,"user":{"displayName":"Zongzhen Lin","userId":"14005131449780649529"}}},"outputs":[],"source":["warnings.filterwarnings('ignore')\n","#Ignore all warnings unless use warnings.filterwarnings(action='once')"],"id":"a5a06d0e"},{"cell_type":"code","execution_count":47,"metadata":{"id":"INVKHzmlTRni","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1674190469324,"user_tz":300,"elapsed":1974,"user":{"displayName":"Zongzhen Lin","userId":"14005131449780649529"}},"outputId":"07e1b7f3-0834-46ef-a2fc-ffaacd6bf036"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"id":"INVKHzmlTRni"},{"cell_type":"code","execution_count":48,"metadata":{"id":"e0c606a7","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1674190469820,"user_tz":300,"elapsed":501,"user":{"displayName":"Zongzhen Lin","userId":"14005131449780649529"}},"outputId":"41a7f56a-cdcc-49f8-dc62-10605b9de522"},"outputs":[{"output_type":"stream","name":"stdout","text":["Dataframe dimension: (942722, 14)\n"]}],"source":["df = pd.read_csv(\"/content/drive/MyDrive/BestBuy Project Week/Hackathon Data_raw.csv\", thousands=',')\n","print('Dataframe dimension:', df.shape)"],"id":"e0c606a7"},{"cell_type":"code","execution_count":49,"metadata":{"id":"sPXgenTKNM-M","colab":{"base_uri":"https://localhost:8080/","height":591},"executionInfo":{"status":"ok","timestamp":1674190469821,"user_tz":300,"elapsed":8,"user":{"displayName":"Zongzhen Lin","userId":"14005131449780649529"}},"outputId":"10cb5622-7cc4-4263-92c9-0605443e0256"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["        Encoded_SKU_ID SALES_DATE      SUBCLASS_NAME          CLASS_NAME  \\\n","0                214.0    5/28/17          MISC ACCY  MOBILE ACCESSORIES   \n","1                329.0    5/28/17           SO PARTS  MOBILE ACCESSORIES   \n","2                 66.0    5/28/17  MIRRORLESS LENSES              LENSES   \n","3                406.0    5/28/17       DECK HARNESS  MOBILE ACCESSORIES   \n","4                292.0    5/28/17           SO PARTS  MOBILE ACCESSORIES   \n","...                ...        ...                ...                 ...   \n","942717             NaN        NaN                NaN                 NaN   \n","942718             NaN        NaN                NaN                 NaN   \n","942719             NaN        NaN                NaN                 NaN   \n","942720             NaN        NaN                NaN                 NaN   \n","942721             NaN        NaN                NaN                 NaN   \n","\n","                        ML_NAME         CATEGORY_NAME  RETAIL_PRICE  \\\n","0            ML - Connected Car  VP - Electrify & Car         19.99   \n","1            ML - Connected Car  VP - Electrify & Car         16.99   \n","2       ML - ILC Cameras/Lenses  VP - Digital Imaging        399.99   \n","3            ML - Connected Car  VP - Electrify & Car         34.99   \n","4            ML - Connected Car  VP - Electrify & Car         49.99   \n","...                         ...                   ...           ...   \n","942717                      NaN                   NaN           NaN   \n","942718                      NaN                   NaN           NaN   \n","942719                      NaN                   NaN           NaN   \n","942720                      NaN                   NaN           NaN   \n","942721                      NaN                   NaN           NaN   \n","\n","       PROMO_PRICE COMPETITOR_PRICE      Inventory  DAILY_UNITS  Unnamed: 11  \\\n","0                ?                ?   Out-of-Stock          0.0          NaN   \n","1                ?                ?   Out-of-Stock          0.0          NaN   \n","2                ?                ?  Fully-Stocked          0.0          NaN   \n","3                ?                ?   Out-of-Stock          0.0          NaN   \n","4                ?                ?   Out-of-Stock          0.0          NaN   \n","...            ...              ...            ...          ...          ...   \n","942717         NaN              NaN            NaN          NaN          NaN   \n","942718         NaN              NaN            NaN          NaN          NaN   \n","942719         NaN              NaN            NaN          NaN          NaN   \n","942720         NaN              NaN            NaN          NaN          NaN   \n","942721         NaN              NaN            NaN          NaN          NaN   \n","\n","        Unnamed: 12  Unnamed: 13  \n","0               NaN          NaN  \n","1               NaN          NaN  \n","2               NaN          NaN  \n","3               NaN          NaN  \n","4               NaN          NaN  \n","...             ...          ...  \n","942717          NaN          NaN  \n","942718          NaN          NaN  \n","942719          NaN          NaN  \n","942720          NaN          NaN  \n","942721          NaN          NaN  \n","\n","[942722 rows x 14 columns]"],"text/html":["\n","  <div id=\"df-50350383-dc57-471d-8359-891eadc413e9\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Encoded_SKU_ID</th>\n","      <th>SALES_DATE</th>\n","      <th>SUBCLASS_NAME</th>\n","      <th>CLASS_NAME</th>\n","      <th>ML_NAME</th>\n","      <th>CATEGORY_NAME</th>\n","      <th>RETAIL_PRICE</th>\n","      <th>PROMO_PRICE</th>\n","      <th>COMPETITOR_PRICE</th>\n","      <th>Inventory</th>\n","      <th>DAILY_UNITS</th>\n","      <th>Unnamed: 11</th>\n","      <th>Unnamed: 12</th>\n","      <th>Unnamed: 13</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>214.0</td>\n","      <td>5/28/17</td>\n","      <td>MISC ACCY</td>\n","      <td>MOBILE ACCESSORIES</td>\n","      <td>ML - Connected Car</td>\n","      <td>VP - Electrify &amp; Car</td>\n","      <td>19.99</td>\n","      <td>?</td>\n","      <td>?</td>\n","      <td>Out-of-Stock</td>\n","      <td>0.0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>329.0</td>\n","      <td>5/28/17</td>\n","      <td>SO PARTS</td>\n","      <td>MOBILE ACCESSORIES</td>\n","      <td>ML - Connected Car</td>\n","      <td>VP - Electrify &amp; Car</td>\n","      <td>16.99</td>\n","      <td>?</td>\n","      <td>?</td>\n","      <td>Out-of-Stock</td>\n","      <td>0.0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>66.0</td>\n","      <td>5/28/17</td>\n","      <td>MIRRORLESS LENSES</td>\n","      <td>LENSES</td>\n","      <td>ML - ILC Cameras/Lenses</td>\n","      <td>VP - Digital Imaging</td>\n","      <td>399.99</td>\n","      <td>?</td>\n","      <td>?</td>\n","      <td>Fully-Stocked</td>\n","      <td>0.0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>406.0</td>\n","      <td>5/28/17</td>\n","      <td>DECK HARNESS</td>\n","      <td>MOBILE ACCESSORIES</td>\n","      <td>ML - Connected Car</td>\n","      <td>VP - Electrify &amp; Car</td>\n","      <td>34.99</td>\n","      <td>?</td>\n","      <td>?</td>\n","      <td>Out-of-Stock</td>\n","      <td>0.0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>292.0</td>\n","      <td>5/28/17</td>\n","      <td>SO PARTS</td>\n","      <td>MOBILE ACCESSORIES</td>\n","      <td>ML - Connected Car</td>\n","      <td>VP - Electrify &amp; Car</td>\n","      <td>49.99</td>\n","      <td>?</td>\n","      <td>?</td>\n","      <td>Out-of-Stock</td>\n","      <td>0.0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>942717</th>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>942718</th>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>942719</th>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>942720</th>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>942721</th>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>942722 rows × 14 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-50350383-dc57-471d-8359-891eadc413e9')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-50350383-dc57-471d-8359-891eadc413e9 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-50350383-dc57-471d-8359-891eadc413e9');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":49}],"source":["df"],"id":"sPXgenTKNM-M"},{"cell_type":"code","execution_count":50,"metadata":{"id":"_6oJiVCpFFj4","executionInfo":{"status":"ok","timestamp":1674190470136,"user_tz":300,"elapsed":321,"user":{"displayName":"Zongzhen Lin","userId":"14005131449780649529"}}},"outputs":[],"source":["def data_cleaning_stage_1(df):\n","  df = df[df['Encoded_SKU_ID'].notna()]\n","  df['SALES_DATE'] = pd.to_datetime(df['SALES_DATE'])\n","  df['year'] = pd.DatetimeIndex(df['SALES_DATE']).year\n","  df['month'] = pd.DatetimeIndex(df['SALES_DATE']).month\n","  df['DAILY_UNITS'] = df['DAILY_UNITS'].astype(float)\n","  df['Encoded_SKU_ID'] = df['Encoded_SKU_ID'].astype(int)\n","  columns_to_keep = ['Encoded_SKU_ID', 'SALES_DATE', 'SUBCLASS_NAME', 'CLASS_NAME', 'ML_NAME', 'CATEGORY_NAME', 'RETAIL_PRICE', 'PROMO_PRICE', 'COMPETITOR_PRICE', 'Inventory', 'DAILY_UNITS', 'year', 'month']\n","  df = df[columns_to_keep]\n","  return df\n","df = data_cleaning_stage_1(df)"],"id":"_6oJiVCpFFj4"},{"cell_type":"markdown","metadata":{"id":"8FFK0bNNpzNW"},"source":["Since this part is all about merging external data, we condensed them together to save space.\n","## Feature Creation"],"id":"8FFK0bNNpzNW"},{"cell_type":"code","execution_count":51,"metadata":{"id":"0xRuvkJUip6Y","colab":{"base_uri":"https://localhost:8080/","height":357},"executionInfo":{"status":"ok","timestamp":1674190473408,"user_tz":300,"elapsed":3277,"user":{"displayName":"Zongzhen Lin","userId":"14005131449780649529"}},"outputId":"131a42d6-d391-4e61-b35a-f84a30376f63"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["   Encoded_SKU_ID SALES_DATE      SUBCLASS_NAME          CLASS_NAME  \\\n","0             214 2017-05-28          MISC ACCY  MOBILE ACCESSORIES   \n","1             329 2017-05-28           SO PARTS  MOBILE ACCESSORIES   \n","2              66 2017-05-28  MIRRORLESS LENSES              LENSES   \n","3             406 2017-05-28       DECK HARNESS  MOBILE ACCESSORIES   \n","4             292 2017-05-28           SO PARTS  MOBILE ACCESSORIES   \n","\n","                   ML_NAME         CATEGORY_NAME  RETAIL_PRICE PROMO_PRICE  \\\n","0       ML - Connected Car  VP - Electrify & Car         19.99           ?   \n","1       ML - Connected Car  VP - Electrify & Car         16.99           ?   \n","2  ML - ILC Cameras/Lenses  VP - Digital Imaging        399.99           ?   \n","3       ML - Connected Car  VP - Electrify & Car         34.99           ?   \n","4       ML - Connected Car  VP - Electrify & Car         49.99           ?   \n","\n","  COMPETITOR_PRICE      Inventory  DAILY_UNITS  year  month  CPIAUCSL  UNRATE  \\\n","0                ?   Out-of-Stock          0.0  2017      5   244.004     4.4   \n","1                ?   Out-of-Stock          0.0  2017      5   244.004     4.4   \n","2                ?  Fully-Stocked          0.0  2017      5   244.004     4.4   \n","3                ?   Out-of-Stock          0.0  2017      5   244.004     4.4   \n","4                ?   Out-of-Stock          0.0  2017      5   244.004     4.4   \n","\n","        CCI      PCE  GSCPI   CSI  \n","0  101.2195  13117.6  -0.09  97.1  \n","1  101.2195  13117.6  -0.09  97.1  \n","2  101.2195  13117.6  -0.09  97.1  \n","3  101.2195  13117.6  -0.09  97.1  \n","4  101.2195  13117.6  -0.09  97.1  "],"text/html":["\n","  <div id=\"df-324d0292-340f-4f9b-8795-1b820bc797cf\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Encoded_SKU_ID</th>\n","      <th>SALES_DATE</th>\n","      <th>SUBCLASS_NAME</th>\n","      <th>CLASS_NAME</th>\n","      <th>ML_NAME</th>\n","      <th>CATEGORY_NAME</th>\n","      <th>RETAIL_PRICE</th>\n","      <th>PROMO_PRICE</th>\n","      <th>COMPETITOR_PRICE</th>\n","      <th>Inventory</th>\n","      <th>DAILY_UNITS</th>\n","      <th>year</th>\n","      <th>month</th>\n","      <th>CPIAUCSL</th>\n","      <th>UNRATE</th>\n","      <th>CCI</th>\n","      <th>PCE</th>\n","      <th>GSCPI</th>\n","      <th>CSI</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>214</td>\n","      <td>2017-05-28</td>\n","      <td>MISC ACCY</td>\n","      <td>MOBILE ACCESSORIES</td>\n","      <td>ML - Connected Car</td>\n","      <td>VP - Electrify &amp; Car</td>\n","      <td>19.99</td>\n","      <td>?</td>\n","      <td>?</td>\n","      <td>Out-of-Stock</td>\n","      <td>0.0</td>\n","      <td>2017</td>\n","      <td>5</td>\n","      <td>244.004</td>\n","      <td>4.4</td>\n","      <td>101.2195</td>\n","      <td>13117.6</td>\n","      <td>-0.09</td>\n","      <td>97.1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>329</td>\n","      <td>2017-05-28</td>\n","      <td>SO PARTS</td>\n","      <td>MOBILE ACCESSORIES</td>\n","      <td>ML - Connected Car</td>\n","      <td>VP - Electrify &amp; Car</td>\n","      <td>16.99</td>\n","      <td>?</td>\n","      <td>?</td>\n","      <td>Out-of-Stock</td>\n","      <td>0.0</td>\n","      <td>2017</td>\n","      <td>5</td>\n","      <td>244.004</td>\n","      <td>4.4</td>\n","      <td>101.2195</td>\n","      <td>13117.6</td>\n","      <td>-0.09</td>\n","      <td>97.1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>66</td>\n","      <td>2017-05-28</td>\n","      <td>MIRRORLESS LENSES</td>\n","      <td>LENSES</td>\n","      <td>ML - ILC Cameras/Lenses</td>\n","      <td>VP - Digital Imaging</td>\n","      <td>399.99</td>\n","      <td>?</td>\n","      <td>?</td>\n","      <td>Fully-Stocked</td>\n","      <td>0.0</td>\n","      <td>2017</td>\n","      <td>5</td>\n","      <td>244.004</td>\n","      <td>4.4</td>\n","      <td>101.2195</td>\n","      <td>13117.6</td>\n","      <td>-0.09</td>\n","      <td>97.1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>406</td>\n","      <td>2017-05-28</td>\n","      <td>DECK HARNESS</td>\n","      <td>MOBILE ACCESSORIES</td>\n","      <td>ML - Connected Car</td>\n","      <td>VP - Electrify &amp; Car</td>\n","      <td>34.99</td>\n","      <td>?</td>\n","      <td>?</td>\n","      <td>Out-of-Stock</td>\n","      <td>0.0</td>\n","      <td>2017</td>\n","      <td>5</td>\n","      <td>244.004</td>\n","      <td>4.4</td>\n","      <td>101.2195</td>\n","      <td>13117.6</td>\n","      <td>-0.09</td>\n","      <td>97.1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>292</td>\n","      <td>2017-05-28</td>\n","      <td>SO PARTS</td>\n","      <td>MOBILE ACCESSORIES</td>\n","      <td>ML - Connected Car</td>\n","      <td>VP - Electrify &amp; Car</td>\n","      <td>49.99</td>\n","      <td>?</td>\n","      <td>?</td>\n","      <td>Out-of-Stock</td>\n","      <td>0.0</td>\n","      <td>2017</td>\n","      <td>5</td>\n","      <td>244.004</td>\n","      <td>4.4</td>\n","      <td>101.2195</td>\n","      <td>13117.6</td>\n","      <td>-0.09</td>\n","      <td>97.1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-324d0292-340f-4f9b-8795-1b820bc797cf')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-324d0292-340f-4f9b-8795-1b820bc797cf button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-324d0292-340f-4f9b-8795-1b820bc797cf');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":51}],"source":["def merge_data(df):\n","  # read cpi\n","  cpi = pd.read_csv('/content/drive/MyDrive/BestBuy Project Week/Raw data/CPIAUCSL.csv', low_memory = False, thousands=',')\n","  cpi['year'] = pd.DatetimeIndex(cpi['DATE']).year # extract year\n","  cpi['month'] = pd.DatetimeIndex(cpi['DATE']).month # extract month\n","  cpi_2017 = cpi[(cpi['DATE'] >= '2017-01-01') & (cpi['DATE'] < '2022-09-01')] # filtered from 2017 to 2022\n","  # merge df and cpi since 2017\n","  df2 = df.merge(cpi_2017, on=['year','month'])\n","  df2 = df2.drop(['DATE'], axis=1)\n","  # read unemployment rate\n","  unemployment = pd.read_csv('/content/drive/MyDrive/BestBuy Project Week/Raw data/UNRATE.csv', low_memory = False, thousands=',')\n","  unemployment['year'] = pd.DatetimeIndex(unemployment['DATE']).year # extract year\n","  unemployment['month'] = pd.DatetimeIndex(unemployment['DATE']).month # extract month\n","  unemployment_2017 = unemployment[(unemployment['DATE'] >= '2017-01-01') & (unemployment['DATE'] < '2022-09-01')] # filtered from 2017 to 2022\n","  # merge df2 and unemployment rate since 2017\n","  df3 = df2.merge(unemployment_2017, on=['year','month'])\n","  df3 = df3.drop(['DATE'], axis=1)\n","  # read consumer confidence index\n","  cci = pd.read_csv('/content/drive/MyDrive/BestBuy Project Week/Raw data/Consumer Confidence Index.csv', low_memory = False, thousands=',')\n","  cci['year'] = pd.DatetimeIndex(cci['TIME']).year # extract year\n","  cci['month'] = pd.DatetimeIndex(cci['TIME']).month # extract month\n","  cci_2017 = cci[(cci['TIME'] >= '2017-01-01') & (cci['TIME'] < '2022-09-01')] # filtered from 2017 to 2022\n","  # merge df3 and unemployment rate since 2017\n","  df4 = df3.merge(cci_2017, on=['year','month'])\n","  df4 = df4.drop(['LOCATION','INDICATOR','SUBJECT','MEASURE','FREQUENCY','TIME','Flag Codes'], axis=1)\n","  df4 = df4.rename(columns={\"Value\": \"CCI\"})\n","  df4\n","  # read personal consumption expenditure\n","  pce = pd.read_csv('/content/drive/MyDrive/BestBuy Project Week/Raw data/Personal Consumption Expenditure - Monthly.csv', low_memory = False, thousands=',')\n","  pce['year'] = pd.DatetimeIndex(pce['DATE']).year # extract year\n","  pce['month'] = pd.DatetimeIndex(pce['DATE']).month # extract month\n","  pce['day'] = pd.DatetimeIndex(pce['DATE']).day # extract day\n","  pce_2017 = pce[(pce['DATE'] >= '2017-01-01') & (pce['DATE'] < '2022-09-01')] # filtered from 2017 to 2022\n","  # merge df4 and unemployeement rate since 2017\n","  df5 = df4.merge(pce_2017, on=['year','month'])\n","  df5 = df5.drop(['DATE'], axis=1)\n","  # read global supply chain pressure index\n","  gscpi = pd.read_csv('/content/drive/MyDrive/BestBuy Project Week/Raw data/Global Supply Chain Pressure Index - Monthly.csv', low_memory = False, thousands=',')\n","  gscpi = gscpi[gscpi['GSCPI'].notna()]\n","  gscpi = gscpi[['Date','GSCPI']]\n","  gscpi['year'] = pd.DatetimeIndex(gscpi['Date']).year # extract year\n","  gscpi['month'] = pd.DatetimeIndex(gscpi['Date']).month # extract month\n","  gscpi_2017 = gscpi[(gscpi['Date'] >= '2017-01-01') & (gscpi['Date'] < '2022-09-01')] # filtered from 2017 to 2022\n","  # merge df4 and unemployment rate since 2017\n","  df6 = df5.merge(gscpi, on=['year','month'])\n","  df6 = df6.drop(['Date', 'day'], axis=1)\n","  # read consumer sentiment index\n","  CSI = pd.read_csv('/content/drive/MyDrive/BestBuy Project Week/Raw data/consumer sentiment index.csv', low_memory = False, thousands=',')\n","  df[\"SALES_DATE\"] = pd.to_datetime(df[\"SALES_DATE\"], format='%Y/%m/%d')\n","  CSI[\"Datemy\"] = pd.to_datetime(CSI[\"Datemy\"], format='%Y/%m/%d')\n","  csi_filtered = CSI.rename(columns={\"Datemy\": \"Date\", 'MONTHLY DATA': 'CSI'})[CSI['MONTHLY DATA'].notna()][['Date', 'CSI']]\n","  csi_filtered['year'] = pd.DatetimeIndex(csi_filtered['Date']).year # extract year\n","  csi_filtered['month'] = pd.DatetimeIndex(csi_filtered['Date']).month # extract month\n","  csi_2017 = csi_filtered[(csi_filtered['Date'] >= '2017-01-01') & (csi_filtered['Date'] < '2022-09-01')] # keep data between 2017 and 2022\n","  # merge df6 and consumer sentiment index table since 2017\n","  df = df6.merge(csi_filtered, on=['year','month'])\n","  df = df.drop(['Date'], axis=1)\n","  return df\n","\n","df = merge_data(df)\n","df.head()"],"id":"0xRuvkJUip6Y"},{"cell_type":"code","execution_count":null,"metadata":{"id":"H6wFCH6r100i"},"outputs":[],"source":["def feature_creation(df):\n","  df['day'] = pd.DatetimeIndex(df['SALES_DATE']).day\n","  #Import US national, state and important holidays for retail\n","  us_holidays = holidays.CountryHoliday('US')\n","  def check_holiday(date):\n","    if date in us_holidays:\n","      return 1\n","    else:\n","      return 0\n","  df['week'] = df['SALES_DATE'].dt.strftime(\"%W\").astype(int) # Monday as the first day of the week\n","  df['Is_holiday'] = df['SALES_DATE'].apply(check_holiday)\n","  #Add a discount percentage feature\n","  condition = (df['PROMO_PRICE'] != '?')\n","  df['PROMO_PRICE'] = df['PROMO_PRICE'].astype(str)\n","  df['PROMO_PRICE'] = df['PROMO_PRICE'].apply(lambda x: x.replace(',', ''))\n","  df.loc[condition, 'PROMO_PRICE'] = df.loc[condition, 'PROMO_PRICE'].astype(float)\n","\n","  #convert retail price from string type to float type\n","  df['RETAIL_PRICE'] = df['RETAIL_PRICE'].astype(str).str.replace(',','').astype(float)\n","  #Initialize Discount feature\n","  df['DISCOUNT'] = df['RETAIL_PRICE']\n","  df.loc[df['PROMO_PRICE'] == '?', 'DISCOUNT'] = 0.0\n","  df.loc[condition, 'DISCOUNT'] = 1 - df.loc[condition, 'PROMO_PRICE'] / df.loc[condition, 'RETAIL_PRICE']\n","  df.loc[:, 'DISCOUNT'] = df.loc[:, 'DISCOUNT'] .astype(float)\n","  return df\n","\n","df = feature_creation(df)\n","df.head()"],"id":"H6wFCH6r100i"},{"cell_type":"code","execution_count":null,"metadata":{"id":"2495d7ae"},"outputs":[],"source":["print(df.columns)\n","display(df.describe())\n","#Added holidays, used national day for test\n","display(df.loc[df['SALES_DATE'] == '2018-07-04',['Encoded_SKU_ID','SALES_DATE', 'Is_holiday','week']].head())"],"id":"2495d7ae"},{"cell_type":"markdown","metadata":{"id":"f6fbd2c4"},"source":["It is useful to examine datatypes & NaN values for each column:"],"id":"f6fbd2c4"},{"cell_type":"code","execution_count":null,"metadata":{"id":"1a95cedb"},"outputs":[],"source":["tab_info=pd.DataFrame(df.dtypes).T.rename(index={0:'column type'})\n","tab_info=tab_info.append(pd.DataFrame((df == '?').sum()).T.rename(index={0:'value is \\'?\\' (nb)'}))\n","tab_info=tab_info.append((pd.DataFrame((df == '?').sum()/df.shape[0]*100).round(2))\n","                         .T.rename(index={0:'Value is \\'?\\' (%)'}))\n","display(tab_info)"],"id":"1a95cedb"},{"cell_type":"markdown","metadata":{"id":"28f4d139"},"source":["___\n","## Exploration "],"id":"28f4d139"},{"cell_type":"markdown","metadata":{"id":"ab7f2d55"},"source":["We want to see the distribution for quantitative variables:"],"id":"ab7f2d55"},{"cell_type":"code","execution_count":null,"metadata":{"id":"60a9e965"},"outputs":[],"source":["fig, axs = plt.subplots(2, figsize = (4,4))\n","plt1 = sns.boxplot(df['RETAIL_PRICE'], ax = axs[0])\n","plt2 = sns.boxplot(df['DAILY_UNITS'], ax = axs[1])\n","plt.tight_layout()"],"id":"60a9e965"},{"cell_type":"code","execution_count":null,"metadata":{"id":"22c480ad"},"outputs":[],"source":["cf = ['SUBCLASS_NAME', 'CLASS_NAME', \n","      'ML_NAME', 'CATEGORY_NAME', 'Inventory']\n","print('\\033[1mVisualising Categorical Features:'.center(100))\n","\n","n=2\n","plt.figure(figsize=[15,10*math.ceil(len(cf)/n)])\n","\n","for i in range(len(cf)):\n","    if df[cf[i]].nunique()<=8:\n","        plt.subplot(math.ceil(len(cf)/n),n,i+1)\n","        sns.countplot(df[cf[i]])\n","        plt.xticks(rotation=90)\n","    else:\n","        plt.subplot(3,1,1)\n","        sns.countplot(df[cf[i]])\n","        plt.xticks(rotation=90)\n","    \n","plt.tight_layout()\n","plt.show()"],"id":"22c480ad"},{"cell_type":"code","execution_count":null,"metadata":{"id":"SYQsgiADf6p3"},"outputs":[],"source":["#Plot the distribution of DAILY_UNITS\n","df_rp = df.groupby('Encoded_SKU_ID')[['Encoded_SKU_ID', 'RETAIL_PRICE']]\n","plt.hist(df.DAILY_UNITS, 30, range=[0, 100], facecolor='blue', align='mid')\n","plt.ylabel('Frequency')\n","plt.xlabel('RETAIL_PRICE($)') # clearly not all data follow the gaussian distribution"],"id":"SYQsgiADf6p3"},{"cell_type":"markdown","metadata":{"id":"6f6b3285"},"source":["## Data Cleaning"],"id":"6f6b3285"},{"cell_type":"markdown","metadata":{"id":"38ffc4a6"},"source":["Important variables to be added:\n","- Weekdays\n","- is_holiday"],"id":"38ffc4a6"},{"cell_type":"code","execution_count":null,"metadata":{"id":"37850853"},"outputs":[],"source":["# Subset is the range of columns we use to check for duplicates\n","subset = ['Encoded_SKU_ID', 'SALES_DATE', 'SUBCLASS_NAME', 'CLASS_NAME', 'ML_NAME', \n","            'CATEGORY_NAME', 'RETAIL_PRICE', 'PROMO_PRICE', 'COMPETITOR_PRICE', 'Inventory', 'DAILY_UNITS']\n","\n","def data_cleaning_stage_2(df):\n","  # To remove duplicates\n","  df.drop_duplicates(subset=subset, inplace=True)\n","  # Clean promo_price\n","  df['BIN_PROMO'] = (df['PROMO_PRICE'] != '?').astype(int)\n","  df.loc[df['PROMO_PRICE'] == '?', 'PROMO_PRICE'] = ''\n","  # Convert sales_date to datetime format\n","  df['SALES_DATE']=pd.to_datetime(df['SALES_DATE'])\n","  # Change weekday to binary format, 0 as weekends and 1 as weekdays\n","  df['weekday'] = df['SALES_DATE'].apply(lambda x: 0 if x.day_name() in ['Saturday', 'Sunday'] else 1)\n","  return df\n","\n","df = data_cleaning_stage_2(df)\n","print(df.duplicated(subset=subset).value_counts())\n","display(df.head())\n","##So no duplicated values"],"id":"37850853"},{"cell_type":"code","execution_count":null,"metadata":{"id":"lYnOGZ0HmM4h"},"outputs":[],"source":["daily_sales = df.groupby('SALES_DATE', as_index=False)['DAILY_UNITS'].sum()\n","cat_daily_sales = df.groupby(['ML_NAME', 'SALES_DATE'], as_index=False)['DAILY_UNITS'].sum()\n","item_daily_sales = df.groupby(['Encoded_SKU_ID', 'SALES_DATE'], as_index=False)['DAILY_UNITS'].sum()\n","\n","daily_sales_sc = go.Scatter(x=daily_sales['SALES_DATE'], y=daily_sales['DAILY_UNITS'])\n","layout = go.Layout(title='Daily sales by date', xaxis=dict(title='Date'), yaxis=dict(title='Sales'))\n","fig = go.Figure(data=[daily_sales_sc], layout=layout)\n","iplot(fig)"],"id":"lYnOGZ0HmM4h"},{"cell_type":"code","execution_count":null,"metadata":{"id":"iL4iqmiNoxp0"},"outputs":[],"source":["cat_daily_sales_sc = []\n","for cat in cat_daily_sales['ML_NAME'].unique():\n","    current_cat_daily_sales = cat_daily_sales[(cat_daily_sales['ML_NAME'] == cat)]\n","    cat_daily_sales_sc.append(go.Scatter(x=cat_daily_sales['SALES_DATE'], y=current_cat_daily_sales['DAILY_UNITS'], name=('Category %s' % cat)))\n","\n","layout = go.Layout(title='daily sales by Categories', xaxis=dict(title='Date'), yaxis=dict(title='Sales'))\n","fig = go.Figure(data=cat_daily_sales_sc, layout=layout)\n","iplot(fig)"],"id":"iL4iqmiNoxp0"},{"cell_type":"markdown","metadata":{"id":"0d3258e8"},"source":["## Feature Engineering"],"id":"0d3258e8"},{"cell_type":"code","execution_count":null,"metadata":{"id":"YBfFqRN9S9BQ"},"outputs":[],"source":["def feature_engineering(df):\n","  # competitor price has 63% missing data so we decide to drop it\n","  df.drop(columns = ['COMPETITOR_PRICE', 'SUBCLASS_NAME', 'CLASS_NAME', 'CATEGORY_NAME', 'PROMO_PRICE'], inplace= True)\n","  #Encode categorical variables\n","  mls = df[\"ML_NAME\"]\n","  df = pd.get_dummies(df, columns=[\"Inventory\", \"ML_NAME\"])\n","  df['ML_NAME'] = mls # in case that we need to run models by each group\n","  return df\n","df = feature_engineering(df)"],"id":"YBfFqRN9S9BQ"},{"cell_type":"code","execution_count":null,"metadata":{"id":"wucpGZXJIrvk"},"outputs":[],"source":["from zmq.constants import NULL\n","df.tail()"],"id":"wucpGZXJIrvk"},{"cell_type":"markdown","metadata":{"id":"44OOwCq4DlBc"},"source":["Encode for categorical variables"],"id":"44OOwCq4DlBc"},{"cell_type":"code","execution_count":null,"metadata":{"id":"ehJQ0ASOJVUE"},"outputs":[],"source":["df['RETAIL_PRICE'].isnull().values.any() #make sure to clear up any null retail price values"],"id":"ehJQ0ASOJVUE"},{"cell_type":"markdown","metadata":{"id":"k_UJEjXED0P4"},"source":["Use standard transformation to scale the data"],"id":"k_UJEjXED0P4"},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZCyO7JjmP4ra"},"outputs":[],"source":["df.dtypes"],"id":"ZCyO7JjmP4ra"},{"cell_type":"code","execution_count":null,"metadata":{"id":"DC8c8Bhvd_RM"},"outputs":[],"source":["features = ['RETAIL_PRICE','CPIAUCSL', 'UNRATE', 'CCI', 'PCE', 'GSCPI', 'CSI', 'DISCOUNT']\n","df_PCA = df[features]\n","Train_X, Test_X, Train_Y, Test_Y = train_test_split(df_PCA, df['DAILY_UNITS'], train_size=0.8, test_size=0.2, random_state=100)"],"id":"DC8c8Bhvd_RM"},{"cell_type":"markdown","metadata":{"id":"yZb9_v3O9glK"},"source":["Apply standardization onto numeric feature data set\n","- we don't use normalization because of many outliers here"],"id":"yZb9_v3O9glK"},{"cell_type":"code","execution_count":null,"metadata":{"id":"LUEI5vg49nHb"},"outputs":[],"source":["standardized_data = StandardScaler().fit_transform(Train_X)\n","Train_X_std = pd.DataFrame(standardized_data, columns = features)"],"id":"LUEI5vg49nHb"},{"cell_type":"code","execution_count":null,"metadata":{"id":"kLWpdIHZcEVJ"},"outputs":[],"source":["plt.subplot(1, 2, 1)\n","(Train_X.RETAIL_PRICE).plot.hist(bins=50, figsize=(12, 6), edgecolor = 'white')\n","plt.xlabel('price', fontsize=12)\n","plt.title('Price Distribution', fontsize=12)\n","\n","plt.subplot(1, 2, 2)\n","Train_X_std.RETAIL_PRICE.plot.hist(bins=50, figsize=(12,6), edgecolor='white')\n","plt.xlabel('Standardized Price', fontsize=12)\n","plt.title('Price Distribution', fontsize=12)"],"id":"kLWpdIHZcEVJ"},{"cell_type":"markdown","metadata":{"id":"76eIeG1pcCD0"},"source":["Apply the log y transformation to our numeric feature data set."],"id":"76eIeG1pcCD0"},{"cell_type":"code","execution_count":null,"metadata":{"id":"H1fePkB-gr5G"},"outputs":[],"source":["Train_X_log = (Train_X + 1).apply(np.log)"],"id":"H1fePkB-gr5G"},{"cell_type":"code","execution_count":null,"metadata":{"id":"nUvGZr--pBow"},"outputs":[],"source":["plt.subplot(1, 2, 1)\n","(Train_X.RETAIL_PRICE).plot.hist(bins=50, figsize=(12, 6), edgecolor = 'white')\n","plt.xlabel('price', fontsize=12)\n","plt.title('Price Distribution', fontsize=12)\n","\n","plt.subplot(1, 2, 2)\n","Train_X_log.RETAIL_PRICE.plot.hist(bins=50, figsize=(12,6), edgecolor='white')\n","plt.xlabel('log(price+1)', fontsize=12)\n","plt.title('Price Distribution', fontsize=12)"],"id":"nUvGZr--pBow"},{"cell_type":"markdown","metadata":{"id":"pbHqGuJ3PO2D"},"source":["- By comparing the distribution of the data before and after scaling, the histogram helps us to identify whether log transformation has a more pronounced effect on the data than the standardization does.\n","- Log y transformation results in a better distribution for the unit price variable."],"id":"pbHqGuJ3PO2D"},{"cell_type":"markdown","metadata":{"id":"TLoCBFT8EjI4"},"source":["**Apply PCA**\\\n","Feature elimination using PCA Decomposition\n","Use both standardization and normalization to test which works better.\n","\n","1. Determine the number of components to select \\\n","2. Fit a random forest regressor to summarize the relative importance scores for each input of numeric features"],"id":"TLoCBFT8EjI4"},{"cell_type":"code","execution_count":null,"metadata":{"id":"dDW3mMbrqbTS"},"outputs":[],"source":["# set 98% of explained variance\n","pca_log = PCA(n_components = 0.98)\n","pca_log.fit(Train_X_log)\n","reduced_logy = pca_log.transform(Train_X_log)\n","reduced_logy"],"id":"dDW3mMbrqbTS"},{"cell_type":"code","execution_count":null,"metadata":{"id":"AfdfwQLC_S07"},"outputs":[],"source":["# set 98% of explained variance\n","pca_std = PCA(n_components = 0.98)\n","pca_std.fit(Train_X_std)\n","reduced_std = pca_std.transform(Train_X_std)\n","reduced_std"],"id":"AfdfwQLC_S07"},{"cell_type":"code","execution_count":null,"metadata":{"id":"ymOg6aBcrzT_"},"outputs":[],"source":["pca_logy_1 = PCA().fit(Train_X_log)\n","\n","plt.rcParams[\"figure.figsize\"] = (12,6)\n","\n","fig, ax = plt.subplots()\n","n = pca_logy_1.n_components_+1\n","xi = np.arange(1, n, step=1)\n","y = np.cumsum(pca_logy_1.explained_variance_ratio_)\n","ax.bar(xi, pca_logy_1.explained_variance_ratio_, lw=2, label='Explained Variance')\n","\n","plt.ylim(0.0,1.1)\n","plt.plot(xi, y, marker='o', linestyle='--', color='b')\n","\n","plt.xlabel('Number of Components')\n","plt.xticks(np.arange(0, n, step=1)) #change from 0-based array index to 1-based human-readable label\n","plt.ylabel('Cumulative variance (%)')\n","plt.title('The number of components needed to explain variance')\n","\n","plt.axhline(y=0.98, color='r', linestyle='-')\n","plt.text(3, 0.85, '98% cut-off threshold', color = 'red', fontsize=16)\n","\n","plt.legend()\n","ax.grid(axis='x')\n","plt.show()"],"id":"ymOg6aBcrzT_"},{"cell_type":"code","execution_count":null,"metadata":{"id":"Sd-P9ACX_rIH"},"outputs":[],"source":["pca_std_1 = PCA().fit(Train_X_std)\n","\n","plt.rcParams[\"figure.figsize\"] = (12,6)\n","\n","fig, ax = plt.subplots()\n","n = pca_logy_1.n_components_+1\n","xi = np.arange(1, n, step=1)\n","y = np.cumsum(pca_std_1.explained_variance_ratio_)\n","ax.bar(xi, pca_std_1.explained_variance_ratio_, lw=2, label='Explained Variance')\n","\n","plt.ylim(0.0,1.1)\n","plt.plot(xi, y, marker='o', linestyle='--', color='b')\n","\n","plt.xlabel('Number of Components')\n","plt.xticks(np.arange(0, n, step=1)) #change from 0-based array index to 1-based human-readable label\n","plt.ylabel('Cumulative variance (%)')\n","plt.title('The number of components needed to explain variance')\n","\n","plt.axhline(y=0.98, color='r', linestyle='-')\n","plt.text(0.5, 0.85, '98% cut-off threshold', color = 'red', fontsize=16)\n","\n","plt.legend()\n","ax.grid(axis='x')\n","plt.show()"],"id":"Sd-P9ACX_rIH"},{"cell_type":"markdown","metadata":{"id":"KwR5lzHd_teY"},"source":["- By comparing the amount of variance explained by the principal components before and after scaling, we can tell that generally the more variance explained by the principal components, the better the scaling method is considered to be. \n","- The explained variance of the principal component after using log y transformation is greater than that of the principal component after applying standardization on the input data.\n"],"id":"KwR5lzHd_teY"},{"cell_type":"markdown","metadata":{"id":"dTnGyNSOAxYg"},"source":["Apply gradient boosting method to get the importance of each independent features with a dependent feature."],"id":"dTnGyNSOAxYg"},{"cell_type":"code","execution_count":null,"metadata":{"id":"OqtwzTVhAyeL"},"outputs":[],"source":["from sklearn.ensemble import GradientBoostingRegressor\n","from sklearn.datasets import make_regression\n","# Initialize the model\n","gbr = GradientBoostingRegressor(random_state=0)\n","# Fit the model to the data\n","gbr.fit(Train_X_log, Train_Y)\n","# Get the feature importance\n","importances = gbr.feature_importances_\n","print(importances)\n","print(features)"],"id":"OqtwzTVhAyeL"},{"cell_type":"code","execution_count":null,"metadata":{"id":"Aj0Be0kiA5PZ"},"outputs":[],"source":["feat_importances = pd.Series(gbr.feature_importances_, index =Train_X_log.columns)\n","feat_importances.nlargest(8).plot(kind='barh')\n","plt.show()"],"id":"Aj0Be0kiA5PZ"},{"cell_type":"markdown","source":["Run random forest model on the log-y transformed data set to determine the top features to keep."],"metadata":{"id":"sfFAk9ncSXGj"},"id":"sfFAk9ncSXGj"},{"cell_type":"code","source":["from matplotlib import pyplot\n","# fit random forest model\n","model = RandomForestRegressor(n_estimators=5, random_state=1)\n","model.fit(Train_X_std, Train_Y)\n","# show importance scores\n","print(sorted(model.feature_importances_)[::-1])\n","# plot importance scores\n","feat_importances = pd.Series(model.feature_importances_, index =Train_X_std.columns).nlargest(8)\n","# names = df[features].columns.values\n","names = list(feat_importances.index)\n","ticks = [i for i in range(len(names))]\n","pyplot.bar(ticks, sorted(model.feature_importances_)[::-1])\n","pyplot.xticks(ticks, names)\n","pyplot.show()"],"metadata":{"id":"HBoMtghzSfjw"},"id":"HBoMtghzSfjw","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Ds9iTaD1Rf1d"},"source":["Conclusion: the importance of each one-hot encoded variable is extremely small and we can take them out from our data set."],"id":"Ds9iTaD1Rf1d"},{"cell_type":"code","execution_count":null,"metadata":{"id":"BPonNo_jjm92"},"outputs":[],"source":["# Checking for correlation between important features\n","print('\\033[1mCorrelation Matrix'.center(100))\n","plt.figure(figsize=[20,10])\n","f_list = ['SALES_DATE','RETAIL_PRICE', 'year',\n","       'month', 'CPIAUCSL', 'CCI', 'GSCPI', 'CSI',\n","       'week', 'DISCOUNT', 'weekday']\n","dfcor = df[['DAILY_UNITS']+f_list]\n","sns.heatmap(dfcor.corr(), annot=True, vmin=-1, vmax=1, center=0)\n","plt.show()"],"id":"BPonNo_jjm92"},{"cell_type":"markdown","metadata":{"id":"7pUC3AZtkSdp"},"source":["Conclusion: we decide to choose log y transformation for numeric features because it works better in PCA and it makes the distribution follows a bell curve more."],"id":"7pUC3AZtkSdp"},{"cell_type":"markdown","metadata":{"id":"67843a2d"},"source":["## Modeling"],"id":"67843a2d"},{"cell_type":"markdown","metadata":{"id":"5KF1AVCYIH92"},"source":["**Preparation**\\\n","Using features derived from\\\n","*RETAIL PRICE, CPI, CCI, PCE, DISCOUNT (std but choose 5)*"],"id":"5KF1AVCYIH92"},{"cell_type":"code","execution_count":null,"metadata":{"id":"wXkBTzxKVSWv"},"outputs":[],"source":["feature_cols = ['Encoded_SKU_ID','SALES_DATE','RETAIL_PRICE', 'year',\n","       'month', 'CPIAUCSL', 'UNRATE', 'CCI', 'PCE', 'GSCPI', 'CSI', 'day',\n","       'week', 'Is_holiday', 'DISCOUNT', 'BIN_PROMO', 'weekday',\n","       'Inventory_Constrained', 'Inventory_Fully-Stocked',\n","       'Inventory_Moderate', 'Inventory_Out-of-Stock',\n","       'ML_NAME_ML - Connected Car', 'ML_NAME_ML - DI Accessories',\n","       'ML_NAME_ML - Electrify', 'ML_NAME_ML - ILC Cameras/Lenses',\n","       'ML_NAME_ML - Kitchen', 'ML_NAME_ML - Laundry',\n","       'ML_NAME_ML - P&S and Action Cams and Drones', 'ML_NAME_ML - Premium']"],"id":"wXkBTzxKVSWv"},{"cell_type":"code","execution_count":null,"metadata":{"id":"g9znvBQ2uFDp"},"outputs":[],"source":["validate_df = pd.read_csv(\"/content/drive/MyDrive/BestBuy Project Week/Validation_Data_raw.csv\", thousands=',')\n","validate_df = data_cleaning_stage_1(validate_df)\n","validate_df = merge_data(validate_df)\n","validate_df = feature_creation(validate_df)\n","validate_df = data_cleaning_stage_2(validate_df)\n","validate_df = feature_engineering(validate_df)\n","Test_Y = validate_df[['Encoded_SKU_ID','SALES_DATE','DAILY_UNITS']].set_index(['Encoded_SKU_ID','SALES_DATE'])\n","validate_df.head()"],"id":"g9znvBQ2uFDp"},{"cell_type":"code","execution_count":null,"metadata":{"id":"B67bsVfHvktc"},"outputs":[],"source":["validate_df_pro = validate_df.copy()\n","validate_df = validate_df[feature_cols]"],"id":"B67bsVfHvktc"},{"cell_type":"code","execution_count":null,"metadata":{"id":"JuM0DA9NkxAv"},"outputs":[],"source":["print(df.columns)\n","Train_X = df[feature_cols].loc[(df['year'] == 2022) & (df['month'].isin([5,6,7]))].set_index(['SALES_DATE','Encoded_SKU_ID'])\n","Train_Y = df.loc[(df['year'] == 2022) & (df['month'].isin([5,6,7]))]['DAILY_UNITS']\n","Test_X = validate_df.set_index(['SALES_DATE', 'Encoded_SKU_ID'])\n","Train_X.head()"],"id":"JuM0DA9NkxAv"},{"cell_type":"code","execution_count":null,"metadata":{"id":"733b8fd9"},"outputs":[],"source":["params = {\"objective\": \"reg:linear\",\n","          \"booster\" : \"gbtree\",\n","          \"eta\": 0.1,\n","          \"max_depth\": 4,\n","          \"subsample\": 0.9,\n","          \"colsample_bytree\": 0.7,\n","          \"silent\": 1,\n","          \"seed\": 10\n","          }\n","num_boost_round = 512\n","\n","def rmse(predictions, targets):\n","    return np.sqrt(((predictions - targets) ** 2).mean())\n","\n","dtrain = xgb.DMatrix(Train_X, Train_Y)\n","dvalid = xgb.DMatrix(Test_X, Test_Y)\n","watchlist = [(dtrain, 'train'), (dvalid, 'eval')]\n","\n","print(\"Train a XGBoost model\")\n","start = time()\n","watchlist = [(dtrain, 'train'), (dvalid, 'eval')]\n","gbm = xgb.train(params, dtrain, num_boost_round, evals=watchlist, early_stopping_rounds=300)\n","end = time()\n","print('Training time is {:2f} s.'.format(end-start))"],"id":"733b8fd9"},{"cell_type":"code","execution_count":null,"metadata":{"id":"kFPxxYA1bUJV"},"outputs":[],"source":["print(\"validating\")\n","yhat = gbm.predict(xgb.DMatrix(Test_X))\n","yhat = np.around(yhat, 0)\n","rmse_val = rmse(np.array(yhat), np.array(Test_Y))\n","print(\"RMSE error is: \" + str(rmse_val))\n","def rmse(predictions, targets):\n","    return np.sqrt(((predictions - targets) ** 2).mean())\n","res = pd.DataFrame(Test_Y)\n","res['Prediction']=yhat\n","display(res.head())\n","print(res.shape)"],"id":"kFPxxYA1bUJV"},{"cell_type":"code","execution_count":null,"metadata":{"id":"I4ld7mBwbWO8"},"outputs":[],"source":["res = pd.DataFrame(data = Test_Y)\n","col_1 = ['DAILY_UNITS','Prediction']\n","res['Prediction']=yhat\n","display(res.head())\n","res.set_index(Test_X.index, inplace = True)\n","res = pd.concat([Test_X, res], axis=1)#[['DAILY_UNITS','Prediction']].iloc[:,1:3]\n","res.to_csv('file_name.csv')\n","res.reset_index(level = ['Encoded_SKU_ID','SALES_DATE'], inplace = True)\n","display(res.head())\n","print(res.shape)\n","L=np.random.randint(low=1,high = max(res['Encoded_SKU_ID']), size = 3 ) "],"id":"I4ld7mBwbWO8"},{"cell_type":"markdown","metadata":{"id":"SeyX9M0piL70"},"source":["## Individual Prophet Prediction"],"id":"SeyX9M0piL70"},{"cell_type":"code","execution_count":null,"metadata":{"id":"S2lh6VFPiRso"},"outputs":[],"source":["df_2021 = df[(df['SALES_DATE'] >= '2021-01-01')]\n","\n","df_2021_id = df_2021[df_2021['Encoded_SKU_ID']==4]\n","df_2021_id_2 = df_2021_id[['SALES_DATE','DAILY_UNITS']]\n","\n","# to SALES_DATE\n","df_2021_id_2['SALES_DATE'] = pd.DatetimeIndex(df_2021_id_2['SALES_DATE'])\n","\n","# from the prophet documentation every variables should have specific names\n","sales = df_2021_id_2.rename(columns = {'SALES_DATE': 'ds','DAILY_UNITS': 'y'})\n","sales.tail()\n","\n","# interval_width = 0.95\n","# using weekly_seasonality instead of monthly or yearly\n","my_model = Prophet(interval_width = 0.95, weekly_seasonality=True, changepoint_prior_scale=0.5)\n","my_model.fit(sales)\n","\n","# dataframe that extends into future 7 days \n","future_dates = my_model.make_future_dataframe(periods = 7)\n","\n","# predictions\n","forecast = my_model.predict(future_dates)\n","\n","# preditions for last week\n","forecast[['ds', 'yhat', 'yhat_lower', 'yhat_upper']].tail(7)\n","\n","fc = forecast[['ds', 'yhat']]\n","\n","def rmse(predictions, targets):\n","  return np.sqrt(((predictions-targets)**2).mean())\n","\n","y_actual = validate_df_pro[(validate_df_pro['SALES_DATE'].isin(fc['ds'].tail(7))) & (df['Encoded_SKU_ID']==4)][['SALES_DATE','DAILY_UNITS']]\n","y_predicted = fc[['ds','yhat']].tail(7)\n","\n","\n","if len(y_actual) < len(y_predicted):\n","  if len(y_actual) == 0:\n","    y_actual = y_predicted.copy()\n","    y_actual.rename(columns = {'ds': 'SALES_DATE', 'yhat': 'DAILY_UNITS'}, inplace=True)\n","    y_actual['DAILY_UNITS'] = 0\n","  else:\n","    res = y_predicted[~y_predicted.ds.isin(y_actual.SALES_DATE)]\n","    res['yhat'] = 0\n","    res.rename(columns={'ds':'SALES_DATE', 'yhat': 'DAILY_UNITS'}, inplace=True)\n","    y_actual = y_actual.append(res, ignore_index=True).set_index('SALES_DATE').sort_index(level=['SALES_DATE'])\n","if len(y_actual) == len(y_predicted):\n","      y_actual = y_actual.set_index('SALES_DATE').sort_index(level=['SALES_DATE'])\n","print(len(y_actual))\n","print(len(y_predicted))\n","y_predicted['yhat'] = np.round(y_predicted['yhat'])\n","rmse_val = rmse(np.array(y_predicted['yhat']), np.array(y_actual['DAILY_UNITS']))\n","rmse_val"],"id":"S2lh6VFPiRso"},{"cell_type":"markdown","metadata":{"id":"jLVeoreF3A0j"},"source":["## All SKUs Prediction Using Prophet"],"id":"jLVeoreF3A0j"},{"cell_type":"code","execution_count":null,"metadata":{"id":"m7U7RWD23HcE"},"outputs":[],"source":["ID_list = sorted(df_2021['Encoded_SKU_ID'].unique())\n","rmseList = []\n","\n","# this is for visualization uses\n","days = sorted(list(validate_df_pro['SALES_DATE'].unique()))\n","actual_sales_per_day = defaultdict(float)\n","forecast_per_day = defaultdict(float)\n","\n","# get RMSE from predicting daily units during 2022 using 2021&2022 data\n","for id in ID_list:\n","  df_2021_id = df_2021[df_2021['Encoded_SKU_ID']==id]\n","  df_2021_id_2 = df_2021_id[['SALES_DATE','DAILY_UNITS']]\n","\n","  df_2021_id_2['SALES_DATE'] = pd.DatetimeIndex(df_2021_id_2['SALES_DATE'])\n","  sales = df_2021_id_2.rename(columns = {'SALES_DATE': 'ds','DAILY_UNITS': 'y'})\n","\n","  my_model = Prophet(interval_width = 0.95, weekly_seasonality=True, changepoint_prior_scale=0.5)\n","  my_model.fit(sales)\n","\n","  future_dates = my_model.make_future_dataframe(periods = 7)\n","  forecast = my_model.predict(future_dates)\n","\n","  fc = forecast[['ds', 'yhat']]\n","\n","  # this is for visualization uses\n","  for d in days:\n","    val_fc = fc.loc[(fc.ds == d),'yhat'].sum()\n","    forecast_per_day[d] += val_fc\n","    val_ac = validate_df_pro[(validate_df_pro.SALES_DATE == d) & (validate_df_pro.Encoded_SKU_ID==id)].DAILY_UNITS.sum()\n","    actual_sales_per_day[d] += val_ac\n","\n","  # they are both dataframes with columns date and units\n","  y_actual = validate_df_pro[(validate_df_pro['SALES_DATE'].isin(fc['ds'].tail(7))) & (validate_df_pro['Encoded_SKU_ID']==id)][['SALES_DATE','DAILY_UNITS']]\n","  y_predicted = fc[['ds','yhat']].tail(7)\n","\n","  # in case that this product has no sales on that specific day, make y_actual as 0\n","  if len(y_actual) < len(y_predicted):\n","    if len(y_actual) == 0:\n","      y_actual = y_predicted.copy()\n","      y_actual.rename(columns = {'ds': 'SALES_DATE', 'yhat': 'DAILY_UNITS'}, inplace=True)\n","      y_actual['DAILY_UNITS'] = 0\n","    else:\n","      res = y_predicted[~y_predicted.ds.isin(y_actual.SALES_DATE)]\n","      res['yhat'] = 0\n","      res.rename(columns={'ds':'SALES_DATE', 'yhat': 'DAILY_UNITS'}, inplace=True)\n","      y_actual = y_actual.append(res, ignore_index=True).set_index('SALES_DATE').sort_index(level=['SALES_DATE'])\n","  if len(y_actual) == len(y_predicted):\n","      y_actual = y_actual.set_index('SALES_DATE').sort_index(level=['SALES_DATE'])\n","  rmse_val = rmse(np.array(np.round(y_predicted['yhat'])), np.array(y_actual['DAILY_UNITS']))\n","  \n","  rmseList.append(rmse_val)\n","  # rmse has SKU ID and RMSE\n","\n","result = pd.DataFrame({'ID': ID_list, 'RMSE': np.array(rmseList)})\n","print(result)\n","\n","# this is for visualization uses\n","df1 = pd.DataFrame(forecast_per_day.items(), columns = ['Day', 'Daily Forecast'])\n","df2 = pd.DataFrame(actual_sales_per_day.items(), columns = ['Day', 'Daily Sales'])\n","plot_df = df1.merge(df2, on='Day')"],"id":"m7U7RWD23HcE"},{"cell_type":"code","execution_count":null,"metadata":{"id":"h8CH1szrocXB"},"outputs":[],"source":["plot_df"],"id":"h8CH1szrocXB"},{"cell_type":"code","execution_count":null,"metadata":{"id":"zu52_t8PrbC6"},"outputs":[],"source":["# RMSE value for Prophet\n","print(\"RMSE VALUE: \" + str(np.mean(rmseList)))\n","print(\"NUMBER OF IDs: \" + str(len(rmseList)))"],"id":"zu52_t8PrbC6"},{"cell_type":"code","execution_count":null,"metadata":{"id":"rjo9x4iHuLeP"},"outputs":[],"source":["validate_df[validate_df['SALES_DATE'] == '2022-08-06'].DAILY_UNITS.sum()"],"id":"rjo9x4iHuLeP"},{"cell_type":"code","execution_count":null,"metadata":{"id":"7-nV9v1hTi9X"},"outputs":[],"source":["validate_df"],"id":"7-nV9v1hTi9X"},{"cell_type":"code","execution_count":null,"metadata":{"id":"HFSWYpWX5pAM"},"outputs":[],"source":["result.RMSE.mean()"],"id":"HFSWYpWX5pAM"},{"cell_type":"code","execution_count":null,"metadata":{"id":"qhmWBAqDL2Is"},"outputs":[],"source":["y_predicted"],"id":"qhmWBAqDL2Is"},{"cell_type":"markdown","metadata":{"id":"YJrIsDqmQy0U"},"source":["## Holt-Winters Exponential Smoothing Model\n","- Based on the daily sales from the graph \"daily sales by Categories\", we can tell that seasonal variation is relatively unconstant for products in some categories like DI Accessories.\n","- Hence we use multiplicative decompositions overall."],"id":"YJrIsDqmQy0U"},{"cell_type":"code","execution_count":null,"metadata":{"id":"D-namyeiZpNV"},"outputs":[],"source":["Test_Y_1 = Test_Y.reset_index().groupby('SALES_DATE').sum()\n","Test_Y_1"],"id":"D-namyeiZpNV"},{"cell_type":"code","execution_count":null,"metadata":{"id":"k0w2b310xAD3"},"outputs":[],"source":["df_2020 = df[df.SALES_DATE >= '07-01-2020'][['SALES_DATE','DAILY_UNITS']].groupby('SALES_DATE').sum()\n","df_2020.DAILY_UNITS"],"id":"k0w2b310xAD3"},{"cell_type":"code","execution_count":null,"metadata":{"id":"goLCHOOTQMBp"},"outputs":[],"source":["from statsmodels.tsa.holtwinters import ExponentialSmoothing\n","from statsmodels.tsa.holtwinters import HoltWintersResults\n","train, test = df_2020.DAILY_UNITS, Test_Y_1.DAILY_UNITS\n","model = ExponentialSmoothing(np.asarray(train), seasonal='multiplicative', seasonal_periods=12)\n","model_fit = model.fit(optimized=True)\n","pred = model_fit.predict(start = len(train), end = (len(train) + 7 -1))\n","\n","def rmse(predictions, targets):\n","    return np.sqrt(((predictions - targets) ** 2).mean())\n","print(rmse(pred[0], test))\n","plt.plot(test.index, test, label='Test')\n","plt.plot(test.index, pred, label='Holt-Winters')\n","plt.legend(loc='best')\n","plt.show()\n"],"id":"goLCHOOTQMBp"},{"cell_type":"markdown","metadata":{"id":"9_fwoqqh70Gi"},"source":["Conclusion: \n","- Daily sales have high volatility and is highly non-stationary and had multiple seasonalites. Holt-Winters Model is not the best fit model to predict."],"id":"9_fwoqqh70Gi"}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.6"},"accelerator":"GPU","gpuClass":"standard"},"nbformat":4,"nbformat_minor":5}
